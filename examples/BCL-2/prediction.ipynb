{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "897b37c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/hoon/dd-agent/llm_dd/examples/BCL-2\n",
      "Home directory: /home/hoon/dd-agent/llm_dd\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "cwd = os.getcwd()\n",
    "print(\"Current working directory:\", cwd)\n",
    "home_dir = os.path.dirname(os.path.dirname(cwd))\n",
    "print(\"Home directory:\", home_dir)\n",
    "sys.path.append(home_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "382ba884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from agentD.agents import agentD\n",
    "from agentD.analysis_utils import get_tool_decorated_functions, custom_serializer\n",
    "from agentD.prompts import FORMAT_INSTRUCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ca23820",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_tools = get_tool_decorated_functions(os.path.join(home_dir, \"agentD/tools/retrieval.py\"))\n",
    "#comm_tools = get_tool_decorated_functions(os.path.join(home_dir, \"agentD/tools/common.py\"))\n",
    "lit_tools = get_tool_decorated_functions(os.path.join(home_dir, \"agentD/tools/lit_analysis.py\"))\n",
    "pred_tools = get_tool_decorated_functions(os.path.join(home_dir, \"agentD/tools/prediction.py\"))\n",
    "gen_tools = get_tool_decorated_functions(os.path.join(home_dir, \"agentD/tools/generation.py\"))\n",
    "\n",
    "tools = gen_tools + ret_tools + pred_tools #pred_tools #ret_tools + comm_tools + lit_tools\n",
    "\n",
    "tool_names = [tool.name for tool in tools]  \n",
    "tool_desc = [tool.description for tool in tools]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96dc0e2",
   "metadata": {},
   "source": [
    "# Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3887a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_existing_drug_smiles(extraction_file, pool_directory):\n",
    "    with open(extraction_file, \"r\") as f:\n",
    "        extraction_data = json.load(f)\n",
    "    smiles = extraction_data.get(\"SMILES\", None)\n",
    "    if smiles:\n",
    "        # smiles are string or list\n",
    "        if isinstance(smiles, str):\n",
    "            smiles = [smiles]\n",
    "        # Create a DataFrame from the list of SMILES\n",
    "        smiles_df = pd.DataFrame(smiles, columns=[\"SMILES\"])\n",
    "        save_path = os.path.join(pool_directory, \"existing_drug_molecules.csv\")\n",
    "        smiles_df.to_csv(save_path, index=False)\n",
    "    else:\n",
    "        print(\"No existing drug SMILES found in extraction.json.\")\n",
    "\n",
    "\n",
    "def combine_smiles_files(pool_directory):\n",
    "    \"\"\"\n",
    "    Combines SMILES from all CSV files in a directory into a single CSV file.\n",
    "    Adds an index based on the first letter of the file name and row number.\n",
    "\n",
    "    Args:\n",
    "        pool_directory (str): Path to the directory containing the CSV files.\n",
    "\n",
    "    \"\"\"\n",
    "    combined_data = []\n",
    "\n",
    "    # Iterate through all files in the directory\n",
    "    for file_name in os.listdir(pool_directory):\n",
    "        if file_name.endswith(\".csv\") and not file_name.startswith(\"combined_\"):\n",
    "            file_path = os.path.join(pool_directory, file_name)\n",
    "            try:\n",
    "                # Read the CSV file\n",
    "                df = pd.read_csv(file_path)\n",
    "\n",
    "                # Normalize column names to uppercase\n",
    "                df.columns = df.columns.str.upper()\n",
    "                #print(df.columns)\n",
    "\n",
    "                # Ensure the 'SMILES' column exists\n",
    "                if \"SMILES\" not in df.columns:\n",
    "                    print(f\"Skipping {file_name}: No 'SMILES' column found.\")\n",
    "                    continue\n",
    "\n",
    "                combined_data.append(df[[\"SMILES\"]])\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_name}: {e}\")\n",
    "\n",
    "    # Combine all dataframes and save to the output file\n",
    "    if combined_data:\n",
    "        combined_df = pd.concat(combined_data, ignore_index=True)\n",
    "        output_file = os.path.join(pool_directory, \"combined_smiles.csv\")\n",
    "        combined_df.to_csv(output_file, index=False)\n",
    "        print(f\"Combined CSV saved to {output_file}\")\n",
    "    else:\n",
    "        print(\"No valid CSV files found in the directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04b03ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to pool/combined_smiles.csv\n"
     ]
    }
   ],
   "source": [
    "# read extraction.json\n",
    "\n",
    "save_existing_drug_smiles(\"extraction.json\", \"pool\")\n",
    "combine_smiles_files(\"pool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eed0467",
   "metadata": {},
   "source": [
    "# Property Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea1a8b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"\"\"You are AgentD, a highly knowledgeable and methodical AI chemist.\n",
    "Your objective is to make property predictions over the provided SMILES and the target protein.\n",
    "Specifically, the prediction task involves the binding affinity of a ligand to a protein and ADMET properties of the ligand.\n",
    "Always utilize the designated tools, and if uncertain, refrain from generating speculative information.\n",
    "\"\"\"\n",
    "\n",
    "SUFFIX = \"\"\"You MUST adhere strictly to the following protocol to complete the task:\n",
    "\n",
    "1. Retrieve the UniProt IDs for the given protein. This will be used in the binding affinity prediction. \n",
    "2. Decide the most relevant protein for our target. \n",
    "3. Retrieve FASTA sequence of the given protein from relevant database.\n",
    "4. Predict the properties using the appropriate tools.\n",
    "    - Binding Affinity: Use the FASTA sequence obtained in Step 3 and the SMILES file path as inputs.\n",
    "    - ADMET Properties: Apply the SMILES file directly.\n",
    " \n",
    "---\n",
    "### Notes:\n",
    "- Begin by briefly stating the problem and how you will approach it.\n",
    "- Don't skip any steps.\n",
    "- If any step fails or the required data is not available, provide a clear explanation and do not make assumptions.\n",
    "\n",
    "Now begin your task.\n",
    "\n",
    "Question: {input}\n",
    "Thought: {agent_scratchpad}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "616d655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein = \"BCL-2\" \n",
    "diesease = \"Lymphocytic leukemia\"\n",
    "candidate_smiles_file = \"pool/dummy.csv\" \n",
    "Human_prompt = f\"Make predictions for the potential drug molecules for {diesease} targeting the protein {protein}. The candidate SMILES file is '{candidate_smiles_file}'.\"\n",
    "\n",
    "input_data = {\n",
    "            \"input\": Human_prompt,\n",
    "            \"tools\": tools,\n",
    "            \"tool_names\": tool_names,\n",
    "            \"tool_desc\": tool_desc\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31dba536",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "agent = agentD(tools, \n",
    "               model=\"gpt-4o\",\n",
    "               prefix=PREFIX, \n",
    "               suffix=SUFFIX,\n",
    "               format_instructions=FORMAT_INSTRUCTIONS).agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ca08f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m'''\n",
      "Thought: To make predictions for potential drug molecules targeting the BCL-2 protein, I will follow the outlined protocol. First, I will retrieve the UniProt IDs for the BCL-2 protein. Then, I will fetch the FASTA sequence for the most relevant UniProt ID. Finally, I will use the obtained FASTA sequence and the provided SMILES file to predict binding affinity and ADMET properties.\n",
      "\n",
      "Action: get_uniprot_ids\n",
      "Action Input: BCL-2\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m[('P10415', 'Apoptosis regulator Bcl-2')]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe UniProt ID for the BCL-2 protein is P10415, which corresponds to the \"Apoptosis regulator Bcl-2\". I will now fetch the FASTA sequence for this UniProt ID.\n",
      "\n",
      "Action: fetch_uniprot_fasta\n",
      "Action Input: P10415\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m>sp|P10415|BCL2_HUMAN Apoptosis regulator Bcl-2 OS=Homo sapiens OX=9606 GN=BCL2 PE=1 SV=2\n",
      "MAHAGRTGYDNREIVMKYIHYKLSQRGYEWDAGDVGAAPPGAAPAPGIFSSQPGHTPHPA\n",
      "ASRDPVARTSPLQTPAAPGAAAGPALSPVPPVVHLTLRQAGDDFSRRYRRDFAEMSSQLH\n",
      "LTPFTARGRFATVVEELFRDGVNWGRIVAFFEFGGVMCVESVNREMSPLVDNIALWMTEY\n",
      "LNRHLHTWIQDNGGWDAFVELYGPSMRPLFDFSWLSLKTLLSLALVGACITLGAYLGHK\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe FASTA sequence for the BCL-2 protein has been successfully retrieved. Now, I will proceed to predict the binding affinity using this FASTA sequence and the provided SMILES file 'pool/dummy.csv'. After that, I will predict the ADMET properties using the same SMILES file.\n",
      "\n",
      "Action: predict_affinity_batch\n",
      "Action Input: {\"sequence\": \"MAHAGRTGYDNREIVMKYIHYKLSQRGYEWDAGDVGAAPPGAAPAPGIFSSQPGHTPHPAASRDPVARTSPLQTPAAPGAAAGPALSPVPPVVHLTLRQAGDDFSRRYRRDFAEMSSQLHLTPFTARGRFATVVEELFRDGVNWGRIVAFFEFGGVMCVESVNREMSPLVDNIALWMTEYLNRHLHTWIQDNGGWDAFVELYGPSMRPLFDFSWLSLKTLLSLALVGACITLGAYLGHK\", \"smiles_path\": \"pool/dummy.csv\"}\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "100%|██████████| 50/50 [00:05<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m('Affinity predictions saved to ', 'property/affinity_dummy.csv')\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe binding affinity predictions have been successfully saved to 'property/affinity_dummy.csv'. Now, I will proceed to predict the ADMET properties using the same SMILES file 'pool/dummy.csv'.\n",
      "\n",
      "Action: get_admet_predictions\n",
      "Action Input: pool/dummy.csv\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mADMET predictions saved to property/admet_dummy.csv\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mHere's your final answer:\n",
      "Final Answer: The predictions for potential drug molecules targeting the BCL-2 protein have been completed. The binding affinity predictions are saved in 'property/affinity_dummy.csv', and the ADMET properties are saved in 'property/admet_dummy.csv'.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent.invoke(input_data)\n",
    "with open(\"response/prediction.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(response, f, indent=2, default=custom_serializer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reinvent4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
