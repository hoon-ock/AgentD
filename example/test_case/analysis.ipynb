{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78a04e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"combined_sampling\"\n",
    "save_directory = \"analysis_result\"\n",
    "report = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04eb6367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/hoon/dd-agent/llm_dd/example/test_case\n",
      "Home directory: /home/hoon/dd-agent/llm_dd\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "cwd = os.getcwd()\n",
    "print(\"Current working directory:\", cwd)\n",
    "home_dir = os.path.dirname(os.path.dirname(cwd))\n",
    "print(\"Home directory:\", home_dir)\n",
    "sys.path.append(home_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0404236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from rdkit.Chem import QED\n",
    "from rdkit import Chem\n",
    "from agentD.analysis.analysis_helper import rule_based_evaluation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf168e12",
   "metadata": {},
   "source": [
    "# Preliminary - File Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c02dd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Mol2Mol_sampling_update...\n",
      "Processing Reinvent_sampling_update...\n",
      "✅ Stacked files saved with 'Method' column in the save directory.\n"
     ]
    }
   ],
   "source": [
    "names = [\"Mol2Mol_sampling_update\", \"Reinvent_sampling_update\"]\n",
    "\n",
    "# Prepare containers to stack entries\n",
    "all_original_properties = []\n",
    "all_updated_properties = []\n",
    "all_update_mappings = []\n",
    "\n",
    "for n in names:\n",
    "    print(f\"Processing {n}...\")\n",
    "\n",
    "    # Define paths\n",
    "    original_property_path = f\"property/{n}.csv\"\n",
    "    updated_property_path = f\"property/{n}_update.csv\"\n",
    "    update_mapping_path = f\"refinement/{n}.csv\"\n",
    "\n",
    "    # Read and add 'Method' column to identify source\n",
    "    df_original = pd.read_csv(original_property_path)\n",
    "    df_original['Method'] = n\n",
    "    all_original_properties.append(df_original)\n",
    "\n",
    "    df_updated = pd.read_csv(updated_property_path)\n",
    "    df_updated['Method'] = n + \"_update\"\n",
    "    all_updated_properties.append(df_updated)\n",
    "\n",
    "    df_mapping = pd.read_csv(update_mapping_path)\n",
    "    df_mapping['Method'] = n\n",
    "    all_update_mappings.append(df_mapping)\n",
    "\n",
    "# Stack (concatenate) by type\n",
    "stacked_original_df = pd.concat(all_original_properties, ignore_index=True)\n",
    "stacked_updated_df = pd.concat(all_updated_properties, ignore_index=True)\n",
    "stacked_mapping_df = pd.concat(all_update_mappings, ignore_index=True)\n",
    "\n",
    "# Save all combined data\n",
    "# os.makedirs(\"combined\", exist_ok=True)\n",
    "stacked_original_df.to_csv(f\"property/{file_name}.csv\", index=False)\n",
    "stacked_updated_df.to_csv(f\"property/{file_name}_update.csv\", index=False)\n",
    "stacked_mapping_df.to_csv(f\"refinement/{file_name}.csv\", index=False)\n",
    "\n",
    "print(\"✅ Stacked files saved with 'Method' column in the save directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ecc13",
   "metadata": {},
   "source": [
    "# Update vs. Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df2c94ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "data number: 99\n",
      "invalid SMILES: 4\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14:37:41] Can't kekulize mol.  Unkekulized atoms: 11 12 13 14 21\n",
      "[14:37:41] SMILES Parse Error: unclosed ring for input: 'CN(C)S(=O)(=O)NC(=O)c1ccc(N2CCN(C[C@H]3CC[C@@H](C(=O)O)CC3)[C@@H]2Oc2cnc(N)cc2Cl)'\n",
      "[14:37:41] SMILES Parse Error: unclosed ring for input: 'COc1ccc(OCCNC(=O)c2cc3cc(O)ccc3n2Cc2ccccc2)'\n",
      "[14:37:41] SMILES Parse Error: unclosed ring for input: 'COc1ccc(CC(NC(=O)C2CCCCC2)C(=O)NC(CC)C(=O)NCc2ccc(C(N)N)cc2)'\n"
     ]
    }
   ],
   "source": [
    "original_update_mapping_path = f\"refinement/{file_name}.csv\"\n",
    "df = pd.read_csv(original_update_mapping_path)\n",
    "invalid_count = 0\n",
    "for index, row in df.iterrows():\n",
    "    smiles = row['Updated_SMILES']\n",
    "    if pd.isna(smiles):\n",
    "        continue\n",
    "    smiles = smiles.strip()\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        invalid_count += 1\n",
    "\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"data number: {len(df)}\")\n",
    "print(f\"invalid SMILES: {invalid_count}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "report['method'] = file_name\n",
    "report['data_number'] = len(df)\n",
    "report['invalid_smiles'] = invalid_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dd4737",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6d5cf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeyError] Property not found: Toxicity/AMES Mutagenesis Predictions\n",
      "[Missing] Updated SMILES not found: O=C(O)c1ccc(N2CCN(c3ccc(Oc4cnco4)c3)CC2)cc1\n",
      "[Missing] Updated SMILES not found: CN(C)S(=O)(=O)NC(=O)c1ccc(N2CCN(C[C@H]3CC[C@@H](C(=O)O)CC3)[C@@H]2Oc2cnc(N)cc2Cl)\n",
      "[Missing] Updated SMILES not found: COc1ccc(OCCNC(=O)c2cc3cc(O)ccc3n2Cc2ccccc2)\n",
      "[KeyError] Property not found: Invalid SMILES Predictions\n",
      "[KeyError] Property not found: Toxicity/AMES Mutagenesis Predictions\n",
      "[KeyError] Property not found: Toxicity Predictions\n",
      "[Missing] Updated SMILES not found: COc1ccc(CC(NC(=O)C2CCCCC2)C(=O)NC(CC)C(=O)NCc2ccc(C(N)N)cc2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Property</th>\n",
       "      <th>Original_SMILES</th>\n",
       "      <th>Updated_SMILES</th>\n",
       "      <th>Original_Value</th>\n",
       "      <th>Updated_Value</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Absorption/Caco-2 (logPaap)] Predictions</td>\n",
       "      <td>O=C(NS(=O)(=O)c1ccc(N2CCN(Cc3ccccc3Cl)CC2=O)cc...</td>\n",
       "      <td>O=C(NS(=O)(=O)c1ccc(N2CCN(Cc3ccccc3Cl)CC2=O)cc...</td>\n",
       "      <td>-5.76</td>\n",
       "      <td>-5.79</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Absorption/Caco-2 (logPaap)] Predictions</td>\n",
       "      <td>CC(C)CNc1ccc(S(=O)(=O)NC(=O)c2ccc(N3CCN(C)C(=O...</td>\n",
       "      <td>CC(C)CNc1ccc(S(=O)(=O)NC(=O)c2ccc(N3CCN(C)C(=O...</td>\n",
       "      <td>-5.59</td>\n",
       "      <td>-5.74</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Absorption/Caco-2 (logPaap)] Predictions</td>\n",
       "      <td>O=C(NS(=O)(=O)c1ccc(N2CCN(CC3CCC3)CC2=O)cc1)c1...</td>\n",
       "      <td>O=C(Nc1ccc(N2CCN(CC3CCC3)CC2=O)cc1)c1ccc(Cl)nc1Cl</td>\n",
       "      <td>-4.95</td>\n",
       "      <td>-4.54</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Toxicity/hERG Blockers] Predictions</td>\n",
       "      <td>CN(C)CCNc1ccc(S(=O)(=O)NC(=O)c2ccc(N3CCN(C/C=C...</td>\n",
       "      <td>CN(C)CCNc1ccc(S(=O)(=O)NC(=O)c2ccc(N3CCN(C/C=C...</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Absorption/Caco-2 (logPaap)] Predictions</td>\n",
       "      <td>COc1ccccc1S(=O)(=O)NC(=O)c1ccc(N2CCN(C)C(=O)C2...</td>\n",
       "      <td>COc1ccccc1S(=O)(=O)NC(=O)c1ccc(N2CCN(C)C(=O)C2...</td>\n",
       "      <td>-5.21</td>\n",
       "      <td>-5.21</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>[Absorption/Caco-2 (logPaap)] Predictions</td>\n",
       "      <td>COc1ccc(CN2CCc3c(cc(C(=O)N4CCOC5(CCNC5)C4)n3C)...</td>\n",
       "      <td>CCc1ccc(CN2CCc3c(cc(C(=O)N4CCOC5(CCNC5)C4)n3C)...</td>\n",
       "      <td>-5.12</td>\n",
       "      <td>-5.14</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>[Absorption/Caco-2 (logPaap)] Predictions</td>\n",
       "      <td>CC1CNC(CC(=O)Nc2ccc(-c3ccccc3)cc2)c2c(nc3ccccn...</td>\n",
       "      <td>CC1CNC(CC(=O)Nc2ccc(-c3ccccc3)cc2)c2c(nc3ccccn...</td>\n",
       "      <td>-5.1</td>\n",
       "      <td>-5.1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>[Toxicity/AMES Mutagenesis] Predictions</td>\n",
       "      <td>NC(=O)c1[nH]c(=Nc2cccc3ccccc23)sc1C(=O)c1ccccc1F</td>\n",
       "      <td>NC(=O)c1[nH]c(=Nc2cccc3ccccc23)sc1C(=O)c1ccccc1F</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>[General Properties/Log(P)] Predictions</td>\n",
       "      <td>N#Cc1ccc(-c2ccc(CN(C(=O)Cc3ccccc3)c3ccc4c(c3)C...</td>\n",
       "      <td>N#Cc1ccc(-c2ccc(CN(C(=O)Cc3cc(O)ccc3)c3ccc4c(c...</td>\n",
       "      <td>6.63</td>\n",
       "      <td>6.16</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>[General Properties/Log S] Predictions</td>\n",
       "      <td>Cc1c(CCC(C)C)c(=O)oc2cc(OS(=O)(=O)c3ccc(Cl)cc3...</td>\n",
       "      <td>Cc1c(CCC(C)(CO)C)c(=O)oc2cc(OS(=O)(=O)c3ccc(Cl...</td>\n",
       "      <td>-6.19</td>\n",
       "      <td>-6.03</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Property  \\\n",
       "0   [Absorption/Caco-2 (logPaap)] Predictions   \n",
       "1   [Absorption/Caco-2 (logPaap)] Predictions   \n",
       "2   [Absorption/Caco-2 (logPaap)] Predictions   \n",
       "3        [Toxicity/hERG Blockers] Predictions   \n",
       "4   [Absorption/Caco-2 (logPaap)] Predictions   \n",
       "..                                        ...   \n",
       "86  [Absorption/Caco-2 (logPaap)] Predictions   \n",
       "87  [Absorption/Caco-2 (logPaap)] Predictions   \n",
       "88    [Toxicity/AMES Mutagenesis] Predictions   \n",
       "89    [General Properties/Log(P)] Predictions   \n",
       "90     [General Properties/Log S] Predictions   \n",
       "\n",
       "                                      Original_SMILES  \\\n",
       "0   O=C(NS(=O)(=O)c1ccc(N2CCN(Cc3ccccc3Cl)CC2=O)cc...   \n",
       "1   CC(C)CNc1ccc(S(=O)(=O)NC(=O)c2ccc(N3CCN(C)C(=O...   \n",
       "2   O=C(NS(=O)(=O)c1ccc(N2CCN(CC3CCC3)CC2=O)cc1)c1...   \n",
       "3   CN(C)CCNc1ccc(S(=O)(=O)NC(=O)c2ccc(N3CCN(C/C=C...   \n",
       "4   COc1ccccc1S(=O)(=O)NC(=O)c1ccc(N2CCN(C)C(=O)C2...   \n",
       "..                                                ...   \n",
       "86  COc1ccc(CN2CCc3c(cc(C(=O)N4CCOC5(CCNC5)C4)n3C)...   \n",
       "87  CC1CNC(CC(=O)Nc2ccc(-c3ccccc3)cc2)c2c(nc3ccccn...   \n",
       "88   NC(=O)c1[nH]c(=Nc2cccc3ccccc23)sc1C(=O)c1ccccc1F   \n",
       "89  N#Cc1ccc(-c2ccc(CN(C(=O)Cc3ccccc3)c3ccc4c(c3)C...   \n",
       "90  Cc1c(CCC(C)C)c(=O)oc2cc(OS(=O)(=O)c3ccc(Cl)cc3...   \n",
       "\n",
       "                                       Updated_SMILES Original_Value  \\\n",
       "0   O=C(NS(=O)(=O)c1ccc(N2CCN(Cc3ccccc3Cl)CC2=O)cc...          -5.76   \n",
       "1   CC(C)CNc1ccc(S(=O)(=O)NC(=O)c2ccc(N3CCN(C)C(=O...          -5.59   \n",
       "2   O=C(Nc1ccc(N2CCN(CC3CCC3)CC2=O)cc1)c1ccc(Cl)nc1Cl          -4.95   \n",
       "3   CN(C)CCNc1ccc(S(=O)(=O)NC(=O)c2ccc(N3CCN(C/C=C...          Toxic   \n",
       "4   COc1ccccc1S(=O)(=O)NC(=O)c1ccc(N2CCN(C)C(=O)C2...          -5.21   \n",
       "..                                                ...            ...   \n",
       "86  CCc1ccc(CN2CCc3c(cc(C(=O)N4CCOC5(CCNC5)C4)n3C)...          -5.12   \n",
       "87  CC1CNC(CC(=O)Nc2ccc(-c3ccccc3)cc2)c2c(nc3ccccn...           -5.1   \n",
       "88   NC(=O)c1[nH]c(=Nc2cccc3ccccc23)sc1C(=O)c1ccccc1F          Toxic   \n",
       "89  N#Cc1ccc(-c2ccc(CN(C(=O)Cc3cc(O)ccc3)c3ccc4c(c...           6.63   \n",
       "90  Cc1c(CCC(C)(CO)C)c(=O)oc2cc(OS(=O)(=O)c3ccc(Cl...          -6.19   \n",
       "\n",
       "   Updated_Value Direction  \n",
       "0          -5.79      down  \n",
       "1          -5.74      down  \n",
       "2          -4.54        up  \n",
       "3          Toxic         -  \n",
       "4          -5.21         -  \n",
       "..           ...       ...  \n",
       "86         -5.14      down  \n",
       "87          -5.1         -  \n",
       "88         Toxic         -  \n",
       "89          6.16      down  \n",
       "90         -6.03        up  \n",
       "\n",
       "[91 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "original_property_path = f\"property/{file_name}.csv\"\n",
    "original_update_mapping_path = f\"refinement/{file_name}.csv\"\n",
    "updated_property_path = f\"property/{file_name}_update.csv\"\n",
    "\n",
    "# Load data\n",
    "original_property_df = pd.read_csv(original_property_path)\n",
    "updated_property_df = pd.read_csv(updated_property_path)\n",
    "update_mapping_df = pd.read_csv(original_update_mapping_path)\n",
    "\n",
    "# Collect results here\n",
    "results = []\n",
    "for index, row in update_mapping_df.iterrows():\n",
    "    original_smiles = row['SMILES'].strip()\n",
    "    updated_smiles = row['Updated_SMILES'].strip()\n",
    "    property_name = row['Property'].strip().replace(\"'\", \"\")\n",
    "\n",
    "    # Normalize property name if needed\n",
    "    if not any(suffix in property_name for suffix in [\"Predictions\", \"Interpretation\", \"Probability\"]):\n",
    "        property_name += \" Predictions\"\n",
    "\n",
    "    # Validate SMILES presence\n",
    "    if original_smiles not in original_property_df['SMILES'].values:\n",
    "        print(f\"[Missing] Original SMILES not found: {original_smiles}\")\n",
    "        continue\n",
    "    if updated_smiles not in updated_property_df['SMILES'].values:\n",
    "        print(f\"[Missing] Updated SMILES not found: {updated_smiles}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        original_value = original_property_df.loc[\n",
    "            original_property_df['SMILES'] == original_smiles, property_name\n",
    "        ].values[0]\n",
    "\n",
    "        updated_value = updated_property_df.loc[\n",
    "            updated_property_df['SMILES'] == updated_smiles, property_name\n",
    "        ].values[0]\n",
    "\n",
    "        # Determine direction\n",
    "        if isinstance(original_value, (int, float)) and isinstance(updated_value, (int, float)):\n",
    "            if original_value < updated_value:\n",
    "                direction = \"up\"\n",
    "            elif original_value > updated_value:\n",
    "                direction = \"down\"\n",
    "            else:\n",
    "                direction = \"-\"\n",
    "\n",
    "        elif isinstance(original_value, str) and isinstance(updated_value, str):\n",
    "            if original_value == updated_value:\n",
    "                direction = \"-\"\n",
    "            elif original_value == 'Toxic' and updated_value == 'Safe':\n",
    "                direction = \"safe\"\n",
    "            elif original_value == 'Safe' and updated_value == 'Toxic':\n",
    "                direction = \"toxic\"\n",
    "            elif original_value == 'Inhibitor' and updated_value != 'Inhibitor':\n",
    "                direction = \"Non-Inhibitor\"\n",
    "        # else:\n",
    "        #     direction = \"non-numerical\"\n",
    "\n",
    "        # Append to result list\n",
    "        results.append({\n",
    "            \"Property\": property_name,\n",
    "            \"Original_SMILES\": original_smiles,\n",
    "            \"Updated_SMILES\": updated_smiles,\n",
    "            \"Original_Value\": original_value,\n",
    "            \"Updated_Value\": updated_value,\n",
    "            \"Direction\": direction\n",
    "        })\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"[KeyError] Property not found: {property_name}\")\n",
    "        continue\n",
    "    except IndexError:\n",
    "        print(f\"[IndexError] Value missing for SMILES or property: {original_smiles}, {updated_smiles}\")\n",
    "        continue\n",
    "\n",
    "# Convert results to DataFrame\n",
    "result_df = pd.DataFrame(results)\n",
    "\n",
    "# (Optional) Save to CSV\n",
    "result_df.to_csv(f\"{save_directory}/compare_{file_name}.csv\", index=False)\n",
    "\n",
    "# Preview the result\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176e8c96",
   "metadata": {},
   "source": [
    "## Absorption property comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae684e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total entries for '[Absorption/Caco-2 (logPaap)] Predictions': 57\n",
      "Up: 25, Down: 15, No Change: 17\n",
      "\n",
      "Filtered results for '[Absorption/Caco-2 (logPaap)] Predictions' with Original_Value < -5.0: 39 entries\n",
      "Filtered Up: 17, Filtered Down: 9, Filtered No Change: 13\n"
     ]
    }
   ],
   "source": [
    "# === [Caco-2 Permeability Statistics] ===\n",
    "specific_property = \"[Absorption/Caco-2 (logPaap)] Predictions\"\n",
    "threshold_value = -5.0\n",
    "\n",
    "# Filter by property\n",
    "property_df = result_df[result_df['Property'] == specific_property]\n",
    "print(f\"\\nTotal entries for '{specific_property}': {len(property_df)}\")\n",
    "\n",
    "# Count direction values\n",
    "up_count = property_df[property_df['Direction'] == 'up'].shape[0]\n",
    "down_count = property_df[property_df['Direction'] == 'down'].shape[0]\n",
    "no_change_count = property_df[property_df['Direction'] == '-'].shape[0]\n",
    "print(f\"Up: {up_count}, Down: {down_count}, No Change: {no_change_count}\")\n",
    "\n",
    "# Filter by threshold on Original_Value\n",
    "numeric_df = property_df.copy()\n",
    "numeric_df['Original_Value'] = pd.to_numeric(numeric_df['Original_Value'], errors='coerce')\n",
    "filtered_df = numeric_df[numeric_df['Original_Value'] < threshold_value]\n",
    "\n",
    "print(f\"\\nFiltered results for '{specific_property}' with Original_Value < {threshold_value}: {len(filtered_df)} entries\")\n",
    "\n",
    "# Count direction values in filtered set\n",
    "filtered_up_count = filtered_df[filtered_df['Direction'] == 'up'].shape[0]\n",
    "filtered_down_count = filtered_df[filtered_df['Direction'] == 'down'].shape[0]\n",
    "filtered_no_change_count = filtered_df[filtered_df['Direction'] == '-'].shape[0]\n",
    "print(f\"Filtered Up: {filtered_up_count}, Filtered Down: {filtered_down_count}, Filtered No Change: {filtered_no_change_count}\")\n",
    "result = {\n",
    "    \"Property\": specific_property,\n",
    "    \"Total\": len(property_df),\n",
    "    \"Up\": up_count,\n",
    "    \"Down\": down_count,\n",
    "    \"No Change\": no_change_count,\n",
    "    \"Filter Threshold\": threshold_value,\n",
    "    \"Filtered Count\": len(filtered_df),\n",
    "    \"Filtered Up\": filtered_up_count,\n",
    "    \"Filtered Down\": filtered_down_count,\n",
    "    \"Filtered No Change\": filtered_no_change_count\n",
    "}\n",
    "summary_df = pd.DataFrame([result])\n",
    "result.pop('Property')\n",
    "report[specific_property] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bf75cf",
   "metadata": {},
   "source": [
    "## Toxicity property comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35104392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total entries for 'Toxicity': 25\n",
      "Safe: 6, Toxic: 0, No Change: 19\n",
      "\n",
      "Filtered results for 'Toxicity' with Original_Value = 'Toxic': 25 entries\n",
      "Filtered Safe: 6, Filtered Toxic: 0, Filtered No Change: 19\n"
     ]
    }
   ],
   "source": [
    "# === [Toxicity Statistics] ===\n",
    "specific_property = \"Toxicity\"\n",
    "threshold_value = \"Toxic\"\n",
    "\n",
    "# Filter by property (partial match)\n",
    "property_df = result_df[result_df['Property'].str.contains(specific_property, na=False)]\n",
    "print(f\"\\nTotal entries for '{specific_property}': {len(property_df)}\")\n",
    "\n",
    "# Count direction values\n",
    "safe_count = property_df[property_df['Direction'] == 'safe'].shape[0]\n",
    "toxic_count = property_df[property_df['Direction'] == 'toxic'].shape[0]\n",
    "no_change_count = property_df[property_df['Direction'] == '-'].shape[0]\n",
    "print(f\"Safe: {safe_count}, Toxic: {toxic_count}, No Change: {no_change_count}\")\n",
    "\n",
    "# Filter by exact match on Original_Value\n",
    "filtered_df = property_df[property_df['Original_Value'] == threshold_value]\n",
    "print(f\"\\nFiltered results for '{specific_property}' with Original_Value = '{threshold_value}': {len(filtered_df)} entries\")\n",
    "\n",
    "# Count direction values in filtered set\n",
    "filtered_safe_count = filtered_df[filtered_df['Direction'] == 'safe'].shape[0]\n",
    "filtered_toxic_count = filtered_df[filtered_df['Direction'] == 'toxic'].shape[0]\n",
    "filtered_no_change_count = filtered_df[filtered_df['Direction'] == '-'].shape[0]\n",
    "print(f\"Filtered Safe: {filtered_safe_count}, Filtered Toxic: {filtered_toxic_count}, Filtered No Change: {filtered_no_change_count}\")\n",
    "\n",
    "result = {\n",
    "    \"Property\": specific_property,\n",
    "    \"Total\": len(property_df),\n",
    "    \"Up\": safe_count,\n",
    "    \"Down\": toxic_count,\n",
    "    \"No Change\": no_change_count,\n",
    "    \"Filter Threshold\": threshold_value,\n",
    "    \"Filtered Count\": len(filtered_df),\n",
    "    \"Filtered Up\": filtered_safe_count,\n",
    "    \"Filtered Down\": filtered_toxic_count,\n",
    "    \"Filtered No Change\": filtered_no_change_count\n",
    "}\n",
    "summary_df = pd.DataFrame([result])\n",
    "result.pop('Property')\n",
    "report[specific_property] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e510a4",
   "metadata": {},
   "source": [
    "# Rule-based Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48cbdd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset_with_agent(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads the dataset and applies the LLM-driven analysis to each entry.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the dataset file.\n",
    "        protein (str): Target protein for drug analysis.\n",
    "        objective (str): Target objective for drug analysis.\n",
    "        agent: The LLM agent object.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with the original data and LLM assessments.\n",
    "    \"\"\"\n",
    "    # Read dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Prepare list to store output\n",
    "    results = []\n",
    "\n",
    "    # Iterate through each row\n",
    "    for _, row in df.iterrows():\n",
    "        # rule-based evaluation\n",
    "        entry = row.to_dict()\n",
    "\n",
    "        qed_score = QED.qed(Chem.MolFromSmiles(entry['SMILES']))\n",
    "        report = rule_based_evaluation(entry)\n",
    "        report['QED'] = qed_score\n",
    "        # binding affinity determination\n",
    "        affinity = entry[\"Affinity [pKd]\"]\n",
    "        report['Affinity'] = affinity\n",
    "        \n",
    "        results.append({\"Method\": entry[\"Method\"], **report})\n",
    "\n",
    "    # Create and return the new DataFrame\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b036762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysis_result/combined_sampling.csv\n",
      "analysis_result/combined_sampling_update.csv\n"
     ]
    }
   ],
   "source": [
    "drug_likeness_rules = [\"lipinski_rule_of_5\",\t\n",
    "                      \"veber_rule\",\t\n",
    "                      \"ghose_filter\",\t\n",
    "                      \"rule_of_3\",\n",
    "                      \"oprea_lead_like\"]\n",
    "\n",
    "for suffix in [\"\", \"_update\"]:\n",
    "    # Define property file path\n",
    "    property_file = f\"property/{file_name}{suffix}.csv\"\n",
    "    \n",
    "    # Process the dataset\n",
    "    processed_data = process_dataset_with_agent(property_file)\n",
    "    #processed_data['Method'] = method + suffix\n",
    "    # Save the processed data\n",
    "    save_path = os.path.join(save_directory, os.path.basename(property_file))\n",
    "    num_passed_rules = processed_data[drug_likeness_rules].sum(axis=1)\n",
    "    processed_data['num_passed_rules'] = num_passed_rules\n",
    "    print(save_path) \n",
    "    processed_data.to_csv(save_path, index=False)\n",
    "    \n",
    "    # Compute and store statistics\n",
    "    stats_key = f\"rule_eval{suffix}\" if suffix else \"rule_eval\"\n",
    "    report[stats_key] = processed_data.describe().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b1d11de",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{save_directory}/report_{file_name}.json\", \"w\") as f:\n",
    "    json.dump(report, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9fdc20",
   "metadata": {},
   "source": [
    "# Collective Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a7cac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv(\"analysis_result/combined_sampling.csv\")\n",
    "first_update_data = pd.read_csv(\"analysis_result/combined_sampling_update.csv\")\n",
    "second_update_data = pd.read_csv(\"analysis_result/combined_sampling_update_update.csv\")\n",
    "first_update_result = json.load(open('analysis_result/report_combined_sampling.json'))\n",
    "second_update_result = json.load(open('analysis_result/report_combined_sampling_update.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df7b223",
   "metadata": {},
   "source": [
    "## Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60040fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24, 0.0, 0.76]\n",
      "[0.2, 0.0, 0.8]\n"
     ]
    }
   ],
   "source": [
    "# --- Plot: First vs Second Refinement ---\n",
    "\n",
    "categories = ['Improved', 'Declined', 'Unchanged']\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35  # width of the bars\n",
    "\n",
    "# First refinement ratios\n",
    "tox_data1 = first_update_result['Toxicity']\n",
    "count1 = tox_data1['Filtered Count'] \n",
    "ratios1 = [\n",
    "    tox_data1['Filtered Up'] / count1,\n",
    "    tox_data1['Filtered Down'] / count1,\n",
    "    tox_data1['Filtered No Change'] / count1\n",
    "]\n",
    "print(ratios1)\n",
    "# Second refinement ratios\n",
    "tox_data2 = second_update_result['Toxicity']\n",
    "count2 = tox_data2['Filtered Count']\n",
    "ratios2 = [\n",
    "    tox_data2['Filtered Up'] / count2,\n",
    "    tox_data2['Filtered Down'] / count2,\n",
    "    tox_data2['Filtered No Change'] / count2\n",
    "]\n",
    "print(ratios2)\n",
    "# Colors (updated to be more distinguishable)\n",
    "color1 = '#66c2a5'  # soft green\n",
    "color2 = '#fc8d62'  # soft orange\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "bars1 = plt.bar(x - width/2, ratios1, width, label=f'1st Refinement ({count1})', color=color1, alpha=0.8)\n",
    "bars2 = plt.bar(x + width/2, ratios2, width, label=f'2nd Refinement ({count2})', color=color2, alpha=0.8)\n",
    "\n",
    "# Set labels and ticks\n",
    "plt.ylabel('Ratio', fontsize=15)\n",
    "plt.xticks(x, categories, fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(fontsize=12, loc='upper left', framealpha=0.4)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/toxicity_ratios_1st_vs_2nd.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e224a40",
   "metadata": {},
   "source": [
    "## Permeability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7822344c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43859649122807015, 0.2631578947368421, 0.2982456140350877]\n",
      "[0.5230769230769231, 0.16923076923076924, 0.3076923076923077]\n"
     ]
    }
   ],
   "source": [
    "categories = ['Improved', 'Declined', 'Unchanged']\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35  # width of each bar group\n",
    "\n",
    "# --- Extract from first refinement ---\n",
    "per_data_1st = first_update_result['[Absorption/Caco-2 (logPaap)] Predictions']\n",
    "total_count_1st = per_data_1st['Total']\n",
    "filtered_count_1st = per_data_1st['Filtered Count']\n",
    "\n",
    "total_ratios_1st = [\n",
    "    per_data_1st['Up'] / total_count_1st,\n",
    "    per_data_1st['Down'] / total_count_1st,\n",
    "    per_data_1st['No Change'] / total_count_1st\n",
    "]\n",
    "print(total_ratios_1st)\n",
    "filtered_ratios_1st = [\n",
    "    per_data_1st['Filtered Up'] / filtered_count_1st,\n",
    "    per_data_1st['Filtered Down'] / filtered_count_1st,\n",
    "    per_data_1st['Filtered No Change'] / filtered_count_1st\n",
    "]\n",
    "\n",
    "# --- Extract from second refinement ---\n",
    "per_data_2nd = second_update_result['[Absorption/Caco-2 (logPaap)] Predictions']\n",
    "total_count_2nd = per_data_2nd['Total']\n",
    "filtered_count_2nd = per_data_2nd['Filtered Count']\n",
    "\n",
    "total_ratios_2nd = [\n",
    "    per_data_2nd['Up'] / total_count_2nd,\n",
    "    per_data_2nd['Down'] / total_count_2nd,\n",
    "    per_data_2nd['No Change'] / total_count_2nd\n",
    "]\n",
    "print(total_ratios_2nd)\n",
    "filtered_ratios_2nd = [\n",
    "    per_data_2nd['Filtered Up'] / filtered_count_2nd,\n",
    "    per_data_2nd['Filtered Down'] / filtered_count_2nd,\n",
    "    per_data_2nd['Filtered No Change'] / filtered_count_2nd\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adaded7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot: Total Data ---\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.bar(x - width/2, total_ratios_1st, width, label=f'1st Refinement ({total_count_1st})', color='#66c2a5', alpha=0.8)\n",
    "plt.bar(x + width/2, total_ratios_2nd, width, label=f'2nd Refinement ({total_count_2nd})', color='#fc8d62', alpha=0.8)\n",
    "\n",
    "plt.ylabel('Ratio', fontsize=15)\n",
    "plt.xticks(x, categories, fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(fontsize=12, loc='upper right', framealpha=0.4)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/permeability_ratios_total_1st_vs_2nd.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72daf942",
   "metadata": {},
   "source": [
    "## QED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4af7a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qed_original = original_data['QED']\n",
    "qed_first_update = first_update_data['QED']\n",
    "qed_second_update = second_update_data['QED']\n",
    "bw_adjust_value = 0.4\n",
    "\n",
    "# Create a plot with KDE-style distribution curves using seaborn\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "sns.kdeplot(qed_original, label='Original', linewidth=2, bw_adjust=bw_adjust_value)\n",
    "sns.kdeplot(qed_first_update, label='1st Refinement', linewidth=2, bw_adjust=bw_adjust_value)\n",
    "sns.kdeplot(qed_second_update, label='2nd Refinement', linewidth=2, bw_adjust=bw_adjust_value)\n",
    "\n",
    "plt.xlabel('QED Value', fontsize=20)\n",
    "plt.ylabel('Density', fontsize=20)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.legend(fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/qed_distribution.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b7f2d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QED > 0.6: Original: 23, 1st Update: 33, 2nd Update: 43\n"
     ]
    }
   ],
   "source": [
    "# number of entries QED > 0.6 \n",
    "qed_threshold = 0.6\n",
    "qed_original_count = (qed_original > qed_threshold).sum()\n",
    "qed_first_update_count = (qed_first_update > qed_threshold).sum()\n",
    "qed_second_update_count = (qed_second_update > qed_threshold).sum()\n",
    "\n",
    "print(f\"QED > {qed_threshold}: Original: {qed_original_count}, 1st Update: {qed_first_update_count}, 2nd Update: {qed_second_update_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8320fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_original = original_data['num_passed_rules']\n",
    "rule_first_update = first_update_data['num_passed_rules']\n",
    "rule_second_update = second_update_data['num_passed_rules']\n",
    "\n",
    "# Combine data into a long-form DataFrame for seaborn\n",
    "df_bar = pd.DataFrame({\n",
    "    'Original': rule_original,\n",
    "    '1st Refinement': rule_first_update,\n",
    "    '2nd Refinement': rule_second_update\n",
    "})\n",
    "\n",
    "df_long = df_bar.melt(var_name='Dataset', value_name='Number of Rules Passed')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df_long, x='Number of Rules Passed', hue='Dataset')\n",
    "\n",
    "plt.xlabel('Number of Rules Passed', fontsize=20)\n",
    "plt.ylabel('Count', fontsize=20)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.legend(fontsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/rules_passed_distribution.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d719ac7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of molecules passing >= 4 rules:\n",
      "Dataset\n",
      "1st Refinement    49\n",
      "2nd Refinement    55\n",
      "Original          34\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#. number of moleulce passing >=4 rules\n",
    "num_passed_4_rules = df_long[df_long['Number of Rules Passed'] >= 4].groupby('Dataset').size()\n",
    "print(\"\\nNumber of molecules passing >= 4 rules:\")\n",
    "print(num_passed_4_rules)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reinvent4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
